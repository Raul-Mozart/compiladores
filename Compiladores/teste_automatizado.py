"""
Script de teste automatizado para o sistema de anÃ¡lise lÃ©xica
"""

from teste_analise_lexica import AnalisadorLexico
import os

def teste_automatico():
    """Executa testes automatizados do sistema"""
    print("ðŸ¤– EXECUTANDO TESTES AUTOMATIZADOS")
    print("=" * 50)
    
    # Inicializa o analisador
    analisador = AnalisadorLexico()
    
    print("\n1. ðŸ”§ Testando compilaÃ§Ã£o de tokens...")
    if len(analisador.dfas_compilados) > 15:
        print("   âœ… Tokens compilados com sucesso")
    else:
        print("   âš ï¸  Alguns tokens falharam na compilaÃ§Ã£o")
    
    print("\n2. ðŸ“ Testando tokens individuais...")
    casos_teste = {
        "KEYWORD": ["if", "function", "var"],
        "IDENTIFIER": ["variavel", "_private", "contador1"],
        "INT_LITERAL": ["123", "0", "42"],
        "FLOAT_LITERAL": ["3.14", "1.5", "0.0"]
    }
    
    sucessos = 0
    total = 0
    
    for token_type, exemplos in casos_teste.items():
        for exemplo in exemplos:
            total += 1
            if analisador.validar_token_individual(token_type, exemplo):
                sucessos += 1
                print(f"   âœ… {token_type}: '{exemplo}'")
            else:
                print(f"   âŒ {token_type}: '{exemplo}'")
    
    print(f"\n   ðŸ“Š Taxa de sucesso: {sucessos}/{total} ({100*sucessos/total:.1f}%)")
    
    print("\n3. ðŸ“„ Testando arquivo de exemplo...")
    if os.path.exists("codigo_exemplo.txt"):
        resultado = analisador.processar_arquivo("codigo_exemplo.txt")
        if "erro" in resultado:
            print(f"   âŒ Erro: {resultado['erro']}")
        else:
            print(f"   âœ… Processado: {resultado['total_tokens']} tokens encontrados")
            print(f"   ðŸ“Š Tipos Ãºnicos: {len(resultado['estatisticas'])}")
    else:
        print("   âš ï¸  Arquivo codigo_exemplo.txt nÃ£o encontrado")
    
    print("\n4. ðŸ” Testando cÃ³digo inline...")
    codigo_teste = '''
    var int x as 10;
    if (x > 5) {
        print("maior");
    }
    '''
    
    tokens = analisador.tokenizar_codigo(codigo_teste)
    tokens_validos = [t for t in tokens if t[0] != "UNKNOWN"]
    
    print(f"   ðŸ“ CÃ³digo: {len(codigo_teste)} caracteres")
    print(f"   ðŸ” Tokens: {len(tokens)} encontrados")
    print(f"   âœ… VÃ¡lidos: {len(tokens_validos)}")
    print(f"   âŒ Desconhecidos: {len(tokens) - len(tokens_validos)}")
    
    if len(tokens) > 10:
        print("   âœ… TokenizaÃ§Ã£o funcionando")
    else:
        print("   âš ï¸  Poucos tokens encontrados")
    
    print("\nðŸŽ¯ RESUMO DOS TESTES:")
    print("=" * 30)
    print(f"âœ… Sistema operacional: {sucessos/total > 0.8}")
    print(f"âœ… Arquivos criados: {os.path.exists('codigo_exemplo.txt')}")
    print(f"âœ… TokenizaÃ§Ã£o: {len(tokens) > 5}")
    print("\nðŸš€ Sistema pronto para uso!")

if __name__ == "__main__":
    teste_automatico()